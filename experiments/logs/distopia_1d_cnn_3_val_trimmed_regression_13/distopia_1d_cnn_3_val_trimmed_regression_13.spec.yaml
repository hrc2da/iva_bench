#goal: pretrain a regression model and then pop a softmax + classifier on top and train on labels
experiment_description: pre-standardized. this is INTROSPECTIVE; balancing the class sample size in the test for more accurate accuracy
experiment_type: experiment_types.regression_experiment.DistopiaRegressionExperiment
data:
  backend: data_types.distopia_data.DistopiaData
  task_labels: 
    - [-1,-1,0]
    - [-1,-1,1]
    - [-1,0,0]
    - [-1,0,1]
    - [0,-1,0]
    - [0,-1,1]
    - [0,0,1]
  #training_path: /home/dev/data/distopia/243_raw.pkl
  training_path: /home/dev/data/distopia/greedy_logs/3_obj/agent_merged_introspective_standardized.npy
  training_labels_path: /home/dev/data/distopia/greedy_logs/3_obj/agent_merged_labels.npy
  preprocessors: # these should be in the order you want them called
    ['filter_by_task','filter_by_metrics','sliding_window']
  test_path: /home/dev/data/distopia/team_logs/team_merged_introspective_standardized.npy
  test_labels_path: /home/dev/data/distopia/team_logs/team_merged_labels.npy
  test_preprocessors: ['filter_by_task','filter_by_metrics','sliding_window','onehot2class','balance_samples', 'class2onehot']
  balanced_sample_size: 1000
  #standardization_file: /home/dev/data/distopia/greedy_one_hots_26/standardization_params.pkl
  window_size: 20
  n_workers: 1
  metric_names: ['population','pvi','compactness']
  # window_size: 5
  # window_step: 1
  #slice_bounds: [0,1000]
  # test_proportion:
  #   # the proportion of the data to save as test data
  #   0.2
random_seed:
  42

model:
  backend: models.keras_nn.KerasSequential
  type: Sequential
  layers: 
      - type: Conv1D
        filters: 64 # don't increase the feature maps
        kernel_size: 7
        activation: 'relu'
        input_shape: [20,3] # 40 steps of 3 outcomes
      - type: Conv1D
        filters: 64 # don't increase the feature maps
        kernel_size: 7
        stride: 2
        activation: 'relu'
      - type: Flatten
      - type: Dense
        units: 100
        activation: 'tanh' # output is weight vector from -1 to 1
      - type: Dense
        units: 3
        activation: 'linear' # output is weight vector from -1 to 1
  fit_params:
    epochs: 100
    batch_size: 89089
  loss: 'mean_squared_error'
  optimizer: 'adam'
  metrics: ['mean_squared_error','skl_r2score','coeff_determination','mean_absolute_error','accuracy','cosine_proximity']
